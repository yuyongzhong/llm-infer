# ========== 基本配置 ==========
basic:
  model_name: deepseek                     # 模型名称，用于日志命名、推理调用等
  home_path: /home/yuyongzhong             # 代码根目录，用于构造路径
  log_info: yyz_test_20250723_1000 # 当前测试任务标识，会用于输出日志文件夹命名
  run_mode: skip     # 控制主运行流程：accuracy | benchmark | acc-then-bench | bench-then-acc | skip
  base_info:                               
    device: docker-yyztest(6core)
    model: Qwen-1.5B
    version: v1.0.0
    software_version: "0701"  # 添加双引号（或 '0701'），强制为字符串
    software_url: https://oss.mthreads.com:9001/buckets/release-ci/browse/Y29tcHV0ZVFBL2N1ZGFfY29tcGF0aWJsZS9DSS9yZWxlYXNlX211c2FfNC4xLjA=
    vllm_image_harbor:
      huoshan_harbor_url: registry.mthreads.com/mcconline/vllm-musa-qy2-py310:v0.8.4-release
      shanghai_harbor_url: sh-harbor.mthreads.com/vllm-images/vllm-musa-qy2-py310:v0.8.4-release
  enable_json_output: true                 # 是否生成标准化JSON输出（true/false）
# ========== 精度评估配置 ==========
accuracy:
  api_url: http://127.0.0.1:8000/v1         # 调用大模型服务的 API 地址（用于精度测试）
  temperature: 0.6                         # 控制生成文本的随机性（越大越随机）
  top_p: 0.95                              # nucleus sampling 中的概率阈值
  use_cache: ""                            # 是否使用缓存（保留空字符串时视为不传）
  max_tokens: 3000                         # 每轮生成最大 token 数
  datasets: ceval                          # 评估使用的数据集，多个用逗号分隔
  data_mode: subset                        # 数据集加载模式：subset（只测试一部分）或 all（全量）
  answer_num: 1                            # 每个问题生成答案的次数
  eval_batch_size: 10                       # 精度测试请求时的批处理大小

# ========== 飞书通知相关 ==========
notification:
  webhook_url: https://oapi.dingtalk.com/robot/send?access_token=9ad9373a15c82ad31bca9da0d92f8602432b79c3ae5975bc6160cf9ab5d82b49  # 钉钉机器人 webhook
  check_interval: 60                       # 精度测试运行中监控间隔（秒）

# ========== 性能评估配置 ==========
benchmark:
  base_url: http://127.0.0.1:8000           # 推理服务基地址（无 /v1 后缀）
  tokenizer_path: /home/yuyongzhong/models/DeepSeek-R1-32B  # tokenizer 路径（传给性能测试脚本）
  batch_sizes:                             # 并发请求设置：支持多组 batch size
    - 16
    - 32
  prompt_pairs:                            # 输入输出长度组合：每对 [输入长度, 输出长度]
    - [128, 128]
    - [128, 64]
  num_prompts: 10                          # 每组配置运行请求的样本数

# ##### 完整的配置示例（注释掉，未启用）
# benchmark:
#   batch_sizes:
#     - 1
#     - 4
#     - 8
#     - 16
#     - 32
#   prompt_pairs:
#     - [128, 128]
#     - [256, 256]
#     - [1024, 1024]
#     - [2048, 200]
#     - [2048, 1024]
#   num_prompts: 200