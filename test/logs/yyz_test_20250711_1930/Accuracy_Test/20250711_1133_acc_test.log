2025-07-11 11:33:09,664 - evalscope - INFO - Args: Task config is provided with TaskConfig type.
/usr/local/lib/python3.10/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
2025-07-11 11:33:13,896 - evalscope - INFO - Dump task config to ./outputs/20250711_113309/configs/task_config_1e10d9.yaml
2025-07-11 11:33:13,898 - evalscope - INFO - {
    "model": "deepseek",
    "model_id": "deepseek",
    "model_args": {},
    "model_task": "text_generation",
    "template_type": null,
    "chat_template": null,
    "datasets": [
        "ceval"
    ],
    "dataset_args": {
        "ceval": {
            "name": "ceval",
            "dataset_id": "modelscope/ceval-exam",
            "model_adapter": "generation",
            "output_types": [
                "multiple_choice_logits",
                "generation"
            ],
            "subset_list": [
                "middle_school_history"
            ],
            "metric_list": [
                "AverageAccuracy"
            ],
            "few_shot_num": 0,
            "few_shot_random": false,
            "train_split": "dev",
            "eval_split": "val",
            "prompt_template": "以下是中国关于{subset_name}考试的单项选择题，请选出其中的正确答案。你的回答的最后一行应该是这样的格式：“答案是：LETTER”（不带引号），其中 LETTER 是 A、B、C、D 中的一个。\n{query}",
            "system_prompt": null,
            "query_template": null,
            "pretty_name": "C-Eval",
            "description": null,
            "filters": null,
            "extra_params": {}
        }
    },
    "dataset_dir": "/root/.cache/modelscope/hub/datasets",
    "dataset_hub": "modelscope",
    "generation_config": {
        "max_tokens": 3000,
        "temperature": 0.6,
        "top_p": 0.95,
        "n": 2
    },
    "eval_type": "service",
    "eval_backend": "Native",
    "eval_config": null,
    "stage": "all",
    "limit": null,
    "eval_batch_size": 15,
    "mem_cache": false,
    "use_cache": null,
    "work_dir": "./outputs/20250711_113309",
    "outputs": null,
    "ignore_errors": false,
    "debug": false,
    "dry_run": false,
    "seed": 42,
    "api_url": "http://127.0.0.1:8000/v1",
    "api_key": "KEY",
    "timeout": null,
    "stream": true,
    "judge_strategy": "auto",
    "judge_worker_num": 1,
    "judge_model_args": {},
    "analysis_report": false
}
2025-07-11 11:33:13,899 - evalscope - INFO - Start evaluating on dataset modelscope/ceval-exam
2025-07-11 11:33:13,899 - evalscope - INFO - Loading dataset from hub: modelscope/ceval-exam
2025-07-11 11:33:14,114 - evalscope - INFO - Loading dataset: dataset_name: modelscope/ceval-exam > subsets: ['middle_school_history']
2025-07-11 11:33:32,715 - evalscope - INFO - Use settings: > few_shot_num: 0, > few_shot_split: dev, > target_eval_split: val
['middle_school_history']

===== 传入的参数 =====
api_url: http://127.0.0.1:8000/v1
api_key: KEY
model: deepseek
max_tokens: 3000
datasets: ceval
temperature: 0.6
top_p: 0.95
answer_num: 2
use_cache: 
eval_batch_size: 15
data_mode: subset
acc_log_file: /home/yuyongzhong/llm-infer/test/logs/yyz_test_20250711_1930/Accuracy_Test/20250711_1133_acc_test.log
webhook_url: https://oapi.dingtalk.com/robot/send?access_token=9ad9373a15c82ad31bca9da0d92f8602432b79c3ae5975bc6160cf9ab5d82b49
CHECK_INTERVAL: 60
base_info: 112机器 模型：Qwen-1.5B
=====================

日志文件: /home/yuyongzhong/llm-infer/test/logs/yyz_test_20250711_1930/Accuracy_Test/20250711_1133_acc_test.log
开始监控日志文件，每 5.0 分钟检查一次

检查时间: 2025-07-11 11:33:09

开始第 1 次评估尝试...
本次检查未发现错误

Predicting(middle_school_history):   0%|          | 0/22 [00:00<?, ?it/s]Predicting(middle_school_history):   5%|▍         | 1/22 [00:39<13:58, 39.91s/it]Predicting(middle_school_history):   9%|▉         | 2/22 [00:41<05:53, 17.66s/it]Predicting(middle_school_history):  14%|█▎        | 3/22 [00:43<03:14, 10.23s/it]Predicting(middle_school_history):  18%|█▊        | 4/22 [00:44<01:58,  6.59s/it]Predicting(middle_school_history):  23%|██▎       | 5/22 [00:44<01:14,  4.36s/it]Predicting(middle_school_history):  27%|██▋       | 6/22 [00:46<00:53,  3.35s/it]Predicting(middle_school_history):  32%|███▏      | 7/22 [00:48<00:46,  3.10s/it]Predicting(middle_school_history):  36%|███▋      | 8/22 [00:51<00:41,  2.97s/it]Predicting(middle_school_history):  41%|████      | 9/22 [00:52<00:32,  2.52s/it]Predicting(middle_school_history):  45%|████▌     | 10/22 [00:54<00:26,  2.21s/it]Predicting(middle_school_history):  50%|█████     | 11/22 [00:59<00:32,  2.99s/it]Predicting(middle_school_history):  55%|█████▍    | 12/22 [01:00<00:24,  2.49s/it]Predicting(middle_school_history):  59%|█████▉    | 13/22 [01:01<00:18,  2.03s/it]Predicting(middle_school_history):  64%|██████▎   | 14/22 [01:02<00:14,  1.82s/it]Predicting(middle_school_history):  68%|██████▊   | 15/22 [01:06<00:15,  2.20s/it]Predicting(middle_school_history):  73%|███████▎  | 16/22 [01:08<00:13,  2.22s/it]Predicting(middle_school_history):  77%|███████▋  | 17/22 [01:13<00:15,  3.13s/it]Predicting(middle_school_history):  82%|████████▏ | 18/22 [01:29<00:28,  7.01s/it]Predicting(middle_school_history):  86%|████████▋ | 19/22 [01:30<00:15,  5.15s/it]Predicting(middle_school_history):  91%|█████████ | 20/22 [01:34<00:09,  4.77s/it]Predicting(middle_school_history):  95%|█████████▌| 21/22 [01:34<00:03,  3.42s/it]Predicting(middle_school_history): 100%|██████████| 22/22 [01:45<00:00,  5.81s/it]Predicting(middle_school_history): 100%|██████████| 22/22 [01:45<00:00,  4.81s/it]
2025-07-11 11:35:18,651 - evalscope - INFO - Dump predictions to ./outputs/20250711_113309/predictions/deepseek/ceval_middle_school_history.jsonl.
Reviewing(middle_school_history):   0%|          | 0/22 [00:00<?, ?it/s]Reviewing(middle_school_history): 100%|██████████| 22/22 [00:00<00:00, 2880.43it/s]
2025-07-11 11:35:18,673 - evalscope - INFO - modelscope/ceval-exam report table: 
+----------+-----------+-----------------+-----------------------+-------+---------+------------+
| Model    | Dataset   | Metric          | Subset                |   Num |   Score | Cat.0      |
+==========+===========+=================+=======================+=======+=========+============+
| deepseek | ceval     | AverageAccuracy | middle_school_history |    22 |  0.9091 | Humanities |
+----------+-----------+-----------------+-----------------------+-------+---------+------------+ 

2025-07-11 11:35:18,673 - evalscope - INFO - Skipping report analysis (`analysis_report=False`).
2025-07-11 11:35:18,673 - evalscope - INFO - Dump report to: ./outputs/20250711_113309/reports/deepseek/ceval.json 

2025-07-11 11:35:18,674 - evalscope - INFO - Evaluation finished on modelscope/ceval-exam
2025-07-11 11:35:18,676 - evalscope - INFO - Overall report table: 
+----------+-----------+-----------------+-----------------------+-------+---------+------------+
| Model    | Dataset   | Metric          | Subset                |   Num |   Score | Cat.0      |
+==========+===========+=================+=======================+=======+=========+============+
| deepseek | ceval     | AverageAccuracy | middle_school_history |    22 |  0.9091 | Humanities |
+----------+-----------+-----------------+-----------------------+-------+---------+------------+ 

2025-07-11 11:35:18,677 - evalscope - INFO - Finished evaluation for deepseek on ['ceval']
2025-07-11 11:35:18,677 - evalscope - INFO - Output directory: ./outputs/20250711_113309
检查时间: 2025-07-11 11:38:09

找到 Finished 标记，停止监控

本次检查未发现错误

在日志中找到 work_dir: ./outputs/20250711_113309

找到ceval.json文件，metrics数据如下:
[{'name': 'AverageAccuracy', 'num': 22, 'score': 0.9091, 'macro_score': 0.9091, 'categories': [{'name': ['Humanities'], 'num': 22, 'score': 0.9091, 'macro_score': 0.9091, 'subsets': [{'name': 'middle_school_history', 'score': 0.9091, 'num': 22}]}]}]

112机器 模型：Qwen-1.5B
docker eval 运行检测
 运行正常结束
  评估分数汇总:
    总体分数 : 0.9091
    类别分数:
    - Humanities: 0.9091

已发送钉钉信息

