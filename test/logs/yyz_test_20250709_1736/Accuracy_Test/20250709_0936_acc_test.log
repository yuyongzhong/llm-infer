2025-07-09 09:37:51,704 - evalscope - INFO - Args: Task config is provided with TaskConfig type.
/usr/local/lib/python3.10/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
2025-07-09 09:37:55,996 - evalscope - INFO - Dump task config to ./outputs/20250709_093751/configs/task_config_85fb5a.yaml
2025-07-09 09:37:55,999 - evalscope - INFO - {
    "model": "deepseek",
    "model_id": "deepseek",
    "model_args": {},
    "model_task": "text_generation",
    "template_type": null,
    "chat_template": null,
    "datasets": [
        "ceval"
    ],
    "dataset_args": {
        "ceval": {
            "name": "ceval",
            "dataset_id": "modelscope/ceval-exam",
            "model_adapter": "generation",
            "output_types": [
                "multiple_choice_logits",
                "generation"
            ],
            "subset_list": [
                "middle_school_history"
            ],
            "metric_list": [
                "AverageAccuracy"
            ],
            "few_shot_num": 0,
            "few_shot_random": false,
            "train_split": "dev",
            "eval_split": "val",
            "prompt_template": "以下是中国关于{subset_name}考试的单项选择题，请选出其中的正确答案。你的回答的最后一行应该是这样的格式：“答案是：LETTER”（不带引号），其中 LETTER 是 A、B、C、D 中的一个。\n{query}",
            "system_prompt": null,
            "query_template": null,
            "pretty_name": "C-Eval",
            "description": null,
            "filters": null,
            "extra_params": {}
        }
    },
    "dataset_dir": "/root/.cache/modelscope/hub/datasets",
    "dataset_hub": "modelscope",
    "generation_config": {
        "max_tokens": 3000,
        "temperature": 0.6,
        "top_p": 0.95,
        "n": 2
    },
    "eval_type": "service",
    "eval_backend": "Native",
    "eval_config": null,
    "stage": "all",
    "limit": null,
    "eval_batch_size": 15,
    "mem_cache": false,
    "use_cache": null,
    "work_dir": "./outputs/20250709_093751",
    "outputs": null,
    "ignore_errors": false,
    "debug": false,
    "dry_run": false,
    "seed": 42,
    "api_url": "http://127.0.0.1:8000/v1",
    "api_key": "KEY",
    "timeout": null,
    "stream": true,
    "judge_strategy": "auto",
    "judge_worker_num": 1,
    "judge_model_args": {},
    "analysis_report": false
}
2025-07-09 09:37:55,999 - evalscope - INFO - Start evaluating on dataset modelscope/ceval-exam
2025-07-09 09:37:55,999 - evalscope - INFO - Loading dataset from hub: modelscope/ceval-exam
2025-07-09 09:37:56,215 - evalscope - INFO - Loading dataset: dataset_name: modelscope/ceval-exam > subsets: ['middle_school_history']
2025-07-09 09:38:09,660 - evalscope - INFO - Use settings: > few_shot_num: 0, > few_shot_split: dev, > target_eval_split: val
['middle_school_history']

===== 传入的参数 =====
api_url: http://127.0.0.1:8000/v1
api_key: KEY
model: deepseek
max_tokens: 3000
datasets: ceval
temperature: 0.6
top_p: 0.95
answer_num: 2
use_cache: 
eval_batch_size: 15
data_mode: subset
acc_log_file: /home/yuyongzhong/llm-infer/test/logs/yyz_test_20250709_1736/Accuracy_Test/20250709_0936_acc_test.log
webhook_url: https://oapi.dingtalk.com/robot/send?access_token=9ad9373a15c82ad31bca9da0d92f8602432b79c3ae5975bc6160cf9ab5d82b49
CHECK_INTERVAL: 60
base_info: 112机器 模型：Qwen-1.5B
=====================

日志文件: /home/yuyongzhong/llm-infer/test/logs/yyz_test_20250709_1736/Accuracy_Test/20250709_0936_acc_test.log
开始监控日志文件，每 5.0 分钟检查一次

检查时间: 2025-07-09 09:37:51

开始第 1 次评估尝试...
本次检查未发现错误

Predicting(middle_school_history):   0%|          | 0/22 [00:00<?, ?it/s]Predicting(middle_school_history):   5%|▍         | 1/22 [00:34<12:04, 34.51s/it]Predicting(middle_school_history):   9%|▉         | 2/22 [00:40<05:51, 17.57s/it]Predicting(middle_school_history):  14%|█▎        | 3/22 [00:41<03:15, 10.28s/it]Predicting(middle_school_history):  18%|█▊        | 4/22 [00:45<02:14,  7.49s/it]Predicting(middle_school_history):  23%|██▎       | 5/22 [00:45<01:26,  5.10s/it]Predicting(middle_school_history):  27%|██▋       | 6/22 [00:46<00:56,  3.51s/it]Predicting(middle_school_history):  32%|███▏      | 7/22 [00:46<00:38,  2.56s/it]Predicting(middle_school_history):  36%|███▋      | 8/22 [00:48<00:29,  2.11s/it]Predicting(middle_school_history):  41%|████      | 9/22 [00:48<00:21,  1.68s/it]Predicting(middle_school_history):  45%|████▌     | 10/22 [00:49<00:15,  1.33s/it]Predicting(middle_school_history):  50%|█████     | 11/22 [00:50<00:12,  1.16s/it]Predicting(middle_school_history):  55%|█████▍    | 12/22 [00:58<00:32,  3.26s/it]Predicting(middle_school_history):  59%|█████▉    | 13/22 [00:59<00:24,  2.78s/it]Predicting(middle_school_history):  64%|██████▎   | 14/22 [01:01<00:19,  2.43s/it]Predicting(middle_school_history):  68%|██████▊   | 15/22 [01:13<00:36,  5.21s/it]Predicting(middle_school_history):  73%|███████▎  | 16/22 [01:13<00:22,  3.78s/it]Predicting(middle_school_history):  77%|███████▋  | 17/22 [01:18<00:20,  4.06s/it]Predicting(middle_school_history):  82%|████████▏ | 18/22 [01:21<00:14,  3.70s/it]Predicting(middle_school_history):  86%|████████▋ | 19/22 [01:21<00:08,  2.68s/it]Predicting(middle_school_history):  91%|█████████ | 20/22 [01:28<00:07,  3.92s/it]Predicting(middle_school_history):  95%|█████████▌| 21/22 [01:32<00:03,  3.89s/it]Predicting(middle_school_history): 100%|██████████| 22/22 [01:58<00:00, 10.50s/it]Predicting(middle_school_history): 100%|██████████| 22/22 [01:58<00:00,  5.36s/it]
2025-07-09 09:40:07,685 - evalscope - INFO - Dump predictions to ./outputs/20250709_093751/predictions/deepseek/ceval_middle_school_history.jsonl.
Reviewing(middle_school_history):   0%|          | 0/22 [00:00<?, ?it/s]Reviewing(middle_school_history): 100%|██████████| 22/22 [00:00<00:00, 2497.15it/s]
2025-07-09 09:40:07,708 - evalscope - INFO - modelscope/ceval-exam report table: 
+----------+-----------+-----------------+-----------------------+-------+---------+------------+
| Model    | Dataset   | Metric          | Subset                |   Num |   Score | Cat.0      |
+==========+===========+=================+=======================+=======+=========+============+
| deepseek | ceval     | AverageAccuracy | middle_school_history |    22 |  0.9091 | Humanities |
+----------+-----------+-----------------+-----------------------+-------+---------+------------+ 

2025-07-09 09:40:07,708 - evalscope - INFO - Skipping report analysis (`analysis_report=False`).
2025-07-09 09:40:07,708 - evalscope - INFO - Dump report to: ./outputs/20250709_093751/reports/deepseek/ceval.json 

2025-07-09 09:40:07,709 - evalscope - INFO - Evaluation finished on modelscope/ceval-exam
2025-07-09 09:40:07,711 - evalscope - INFO - Overall report table: 
+----------+-----------+-----------------+-----------------------+-------+---------+------------+
| Model    | Dataset   | Metric          | Subset                |   Num |   Score | Cat.0      |
+==========+===========+=================+=======================+=======+=========+============+
| deepseek | ceval     | AverageAccuracy | middle_school_history |    22 |  0.9091 | Humanities |
+----------+-----------+-----------------+-----------------------+-------+---------+------------+ 

2025-07-09 09:40:07,711 - evalscope - INFO - Finished evaluation for deepseek on ['ceval']
2025-07-09 09:40:07,711 - evalscope - INFO - Output directory: ./outputs/20250709_093751
检查时间: 2025-07-09 09:42:51

找到 Finished 标记，停止监控

本次检查未发现错误

在日志中找到 work_dir: ./outputs/20250709_093751

找到ceval.json文件，metrics数据如下:
[{'name': 'AverageAccuracy', 'num': 22, 'score': 0.9091, 'macro_score': 0.9091, 'categories': [{'name': ['Humanities'], 'num': 22, 'score': 0.9091, 'macro_score': 0.9091, 'subsets': [{'name': 'middle_school_history', 'score': 0.9091, 'num': 22}]}]}]

112机器 模型：Qwen-1.5B
docker eval 运行检测
 运行正常结束
  评估分数汇总:
    总体分数 : 0.9091
    类别分数:
    - Humanities: 0.9091

已发送钉钉信息

