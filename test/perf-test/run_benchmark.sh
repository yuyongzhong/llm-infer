#!/bin/bash

# é»˜è®¤ baseurlï¼ˆå¯é€šè¿‡ --baseurl å‚æ•°è¦†ç›–ï¼‰
BASE_URL="http://127.0.0.1:8000"
MODEL_NAME="deepseek"
HOME_PATH=""
MODEL_DIR_NAME=""

# è§£æå‘½ä»¤è¡Œå‚æ•°
while [[ "$#" -gt 0 ]]; do
  case $1 in
    --model-name) MODEL_NAME="$2"; shift ;;
    --home-path) HOME_PATH="$2"; shift ;;
    --model-dir-name) MODEL_DIR_NAME="$2"; shift ;;
    --baseurl) BASE_URL="$2"; shift ;;
    --help)
      echo "Usage: run_benchmark.sh [--model-name NAME] [--home-path PATH] [--model-dir-name NAME]"
      echo ""
      echo "  --model-name       æ¨¡å‹åç§°ï¼ˆé»˜è®¤ï¼šdeepseekï¼‰"
      echo "  --home-path        ä¸»ç›®å½•è·¯å¾„ï¼Œå¦‚ /home/llm-infer"
      echo "  --model-dir-name   æ¨¡å‹ç›®å½•åï¼Œå¦‚ DeepSeek-R1-32B"
      echo "  --baseurl          è‡ªå®šä¹‰æ¨ç†æœåŠ¡ URLï¼ˆé»˜è®¤ï¼šhttp://127.0.0.1:8000ï¼‰"
      exit 0 ;;
    *) echo "Unknown parameter: $1"; exit 1 ;;
  esac
  shift
done

if [[ -z "$HOME_PATH" || -z "$MODEL_DIR_NAME" ]]; then
  echo "âŒ ERROR: --home-path å’Œ --model-dir-name ä¸ºå¿…å¡«é¡¹ã€‚"
  exit 1
fi

# ç»Ÿä¸€æ—¶é—´æˆ³ï¼ˆå¹´æœˆæ—¥_æ—¶åˆ†ï¼‰
timestamp=$(date '+%Y%m%d_%H%M')

BATCH_SIZES=(1 4 8 16 32)
PROMPT_PAIRS=(
  "128 128"
  "256 256"
  "1024 1024"
  "2048 200"
  "2048 1024"
)
num_prompts=200



# PROMPT_PAIRS=(
#   "16 16"
#   "32 32"
# )
# BATCH_SIZES=(5 10)
# num_prompts=5


# è‡ªåŠ¨ç»„è£…è·¯å¾„
TOKENIZER_PATH="$HOME_PATH/models/$MODEL_DIR_NAME/"
OUTPUT_DIR_FATHER="$HOME_PATH/llm-infer/test/perf-test/benchmark_logs"
OUTPUT_DIR="$OUTPUT_DIR_FATHER/benchmark_logs_${timestamp}"
SCRIPT="$HOME_PATH/llm-infer/test/perf-test/vllm/benchmarks/benchmark_serving.py"
SUMMARY_SCRIPT="$HOME_PATH/llm-infer/test/perf-test/summarize_results.py"
SUMMARY_OUTPUT_MD="$OUTPUT_DIR/summary_result_${timestamp}_.md"

echo "MODEL_NAME=$MODEL_NAME"
echo "TOKENIZER_PATH=$TOKENIZER_PATH"
echo "OUTPUT_DIR=$OUTPUT_DIR"

mkdir -p "$OUTPUT_DIR_FATHER"
mkdir -p "$OUTPUT_DIR"


start_time=$(date +%s)  # â± å¼€å§‹æ—¶é—´æˆ³

for batch_size in "${BATCH_SIZES[@]}"; do
  for pair in "${PROMPT_PAIRS[@]}"; do
    input_len=$(echo "$pair" | awk '{print $1}')
    output_len=$(echo "$pair" | awk '{print $2}')
    LOG_FILE="$OUTPUT_DIR/log_${timestamp}_input${input_len}_output${output_len}_batch${batch_size}.log"
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] Running input_len=$input_len, output_len=$output_len, batch_size=$batch_size..." | tee -a "$LOG_FILE"

    python3 "$SCRIPT" \
      --backend vllm \
      --model "$MODEL_NAME" \
      --tokenizer "$TOKENIZER_PATH" \
      --dataset-name random \
      --random-input-len "$input_len" \
      --random-output-len "$output_len" \
      --num-prompts "$num_prompts" \
      --max-concurrency "$batch_size" \
      --save-result \
      --base-url "$BASE_URL" \
      --ignore-eos \
      --save-detailed \
      --result-filename "$OUTPUT_DIR/result_${timestamp}_input${input_len}_output${output_len}_batch${batch_size}.json" \
      >> "$LOG_FILE" 2>&1

    if [ $? -eq 0 ]; then
      echo "[$(date '+%Y-%m-%d %H:%M:%S')] SUCCESS input_len=$input_len output_len=$output_len batch_size=$batch_size" | tee -a "$LOG_FILE"
    else
      echo "[$(date '+%Y-%m-%d %H:%M:%S')] FAILED input_len=$input_len output_len=$output_len batch_size=$batch_size" | tee -a "$LOG_FILE"
    fi

    echo -e "---\n" >> "$LOG_FILE"
  done
done
# ğŸ” æ±‡æ€»æ‰€æœ‰ç»“æœå¹¶ç”Ÿæˆ markdown è¡¨æ ¼
python3 "$SUMMARY_SCRIPT" --dir "$OUTPUT_DIR" --output "$SUMMARY_OUTPUT_MD"

end_time=$(date +%s)  # â± ç»“æŸæ—¶é—´æˆ³
elapsed=$((end_time - start_time))  # è¿è¡Œç§’æ•°
# æ ¼å¼åŒ–è¾“å‡ºè¿è¡Œæ—¶é—´
echo ""
echo "âœ… è„šæœ¬è¿è¡Œå®Œæˆï¼Œæ€»è€—æ—¶ï¼š${elapsed} ç§’ ($(date -ud "@$elapsed" +'%H:%M:%S'))"