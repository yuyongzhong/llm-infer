Running input_len=128, batch_size=32...
Intel oneMKL FATAL ERROR: Cannot load /usr/local/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so.
�?FAILED input_len=128 batch_size=32
---

Running input_len=128, batch_size=32...
INFO 06-19 02:21:12 [__init__.py:248] No platform detected, vLLM is running on UnspecifiedPlatform
Traceback (most recent call last):
  File "/home/llm-infer/test/perf-test/vllm/benchmarks/benchmark_serving.py", line 50, in <module>
    from vllm.transformers_utils.tokenizer import get_tokenizer
  File "/usr/local/lib/python3.10/site-packages/vllm/__init__.py", line 13, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/usr/local/lib/python3.10/site-packages/vllm/engine/arg_utils.py", line 22, in <module>
    from vllm.config import (BlockSize, CacheConfig, CacheDType, CompilationConfig,
  File "/usr/local/lib/python3.10/site-packages/vllm/config.py", line 1736, in <module>
    class ParallelConfig:
  File "/usr/local/lib/python3.10/site-packages/pydantic/dataclasses.py", line 213, in dataclass
    return create_dataclass(_cls)
  File "/usr/local/lib/python3.10/site-packages/pydantic/dataclasses.py", line 204, in create_dataclass
    pydantic_complete = _pydantic_dataclasses.complete_dataclass(
  File "/usr/local/lib/python3.10/site-packages/pydantic/_internal/_dataclasses.py", line 174, in complete_dataclass
    cls.__pydantic_validator__ = validator = create_schema_validator(
  File "/usr/local/lib/python3.10/site-packages/pydantic/plugin/_schema_validator.py", line 34, in create_schema_validator
    return SchemaValidator(schema, config)
pydantic_core._pydantic_core.SchemaError: Error building "dataclass" validator:
  SchemaError: Error building "dataclass-args" validator:
  SchemaError: Field 'distributed_executor_backend':
  SchemaError: Error building "default" validator:
  SchemaError: Error building "nullable" validator:
  SchemaError: Error building "union" validator:
  SchemaError: Error building "is-subclass" validator:
  TypeError: 'str' object cannot be converted to 'PyType'
�?FAILED input_len=128 batch_size=32
---

Running input_len=128, batch_size=32...
INFO 06-19 03:35:02 [__init__.py:248] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-19 03:35:03 [_custom_ops.py:22] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
Namespace(backend='vllm', base_url='http://10.10.133.112:8000', host='127.0.0.1', port=8000, endpoint='/v1/completions', dataset_name='random', dataset_path=None, max_concurrency=32, model='deepseek', tokenizer='/home/models/DeepSeek-R1-32B/', use_beam_search=False, num_prompts=200, logprobs=None, request_rate=inf, burstiness=1.0, seed=0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=True, save_detailed=False, append_result=False, metadata=None, result_dir=None, result_filename='/home/llm-infer/test/perf-test/benchmark_logs/result_input128_batch32.json', ignore_eos=False, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, custom_output_len=256, custom_skip_chat_template=False, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, random_input_len=128, random_output_len=128, random_range_ratio=0.0, random_prefix_len=0, hf_subset=None, hf_split=None, hf_output_len=None, top_p=None, top_k=None, min_p=None, temperature=None, tokenizer_mode='auto', served_model_name=None, lora_modules=None)
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: inf
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: 32
  0%|          | 0/200 [00:00<?, ?it/s]  0%|          | 1/200 [00:03<10:01,  3.02s/it]  2%|▏         | 4/200 [00:05<03:40,  1.13s/it]  2%|▎         | 5/200 [00:05<03:09,  1.03it/s]  3%|▎         | 6/200 [00:06<03:14,  1.00s/it]  4%|▎         | 7/200 [00:06<02:32,  1.26it/s]  4%|▍         | 8/200 [00:09<03:52,  1.21s/it]  5%|▌         | 10/200 [00:10<03:00,  1.05it/s]  6%|▌         | 11/200 [00:11<03:16,  1.04s/it] 17%|█▋        | 34/200 [00:14<00:37,  4.47it/s] 18%|█▊        | 37/200 [00:15<00:36,  4.44it/s] 19%|█▉        | 38/200 [00:16<00:49,  3.28it/s] 20%|██        | 40/200 [00:17<00:55,  2.89it/s] 20%|██        | 41/200 [00:18<00:59,  2.67it/s] 21%|██        | 42/200 [00:18<00:57,  2.76it/s] 22%|██▏       | 44/200 [00:19<00:58,  2.65it/s] 22%|██▎       | 45/200 [00:20<01:19,  1.94it/s] 23%|██▎       | 46/200 [00:21<01:16,  2.01it/s] 24%|██▍       | 48/200 [00:22<01:17,  1.96it/s] 24%|██▍       | 49/200 [00:22<01:16,  1.97it/s] 25%|██▌       | 50/200 [00:24<01:37,  1.54it/s] 34%|███▍      | 68/200 [00:26<00:28,  4.62it/s] 36%|███▌      | 71/200 [00:27<00:31,  4.11it/s] 36%|███▌      | 72/200 [00:28<00:35,  3.59it/s] 36%|███▋      | 73/200 [00:28<00:35,  3.60it/s] 37%|███▋      | 74/200 [00:29<00:34,  3.60it/s] 38%|███▊      | 76/200 [00:29<00:34,  3.63it/s] 38%|███▊      | 77/200 [00:30<00:40,  3.01it/s] 39%|███▉      | 78/200 [00:30<00:47,  2.57it/s] 40%|███▉      | 79/200 [00:31<00:44,  2.73it/s] 40%|████      | 81/200 [00:31<00:36,  3.30it/s] 42%|████▏     | 83/200 [00:33<01:00,  1.95it/s] 42%|████▏     | 84/200 [00:33<00:57,  2.01it/s] 43%|████▎     | 86/200 [00:34<00:46,  2.48it/s] 44%|████▍     | 88/200 [00:35<00:45,  2.45it/s] 44%|████▍     | 89/200 [00:35<00:48,  2.27it/s] 45%|████▌     | 90/200 [00:36<00:46,  2.37it/s] 46%|████▌     | 91/200 [00:36<00:44,  2.47it/s] 46%|████▌     | 92/200 [00:36<00:40,  2.67it/s] 46%|████▋     | 93/200 [00:37<00:46,  2.32it/s] 53%|█████▎    | 106/200 [00:39<00:21,  4.43it/s] 55%|█████▍    | 109/200 [00:40<00:19,  4.74it/s] 56%|█████▌    | 111/200 [00:40<00:21,  4.07it/s] 56%|█████▌    | 112/200 [00:41<00:25,  3.45it/s] 56%|█████▋    | 113/200 [00:42<00:27,  3.15it/s] 57%|█████▊    | 115/200 [00:42<00:24,  3.51it/s] 58%|█████▊    | 116/200 [00:42<00:23,  3.53it/s] 58%|█████▊    | 117/200 [00:43<00:30,  2.71it/s] 59%|█████▉    | 118/200 [00:44<00:35,  2.33it/s] 60%|█████▉    | 119/200 [00:44<00:32,  2.53it/s] 60%|██████    | 121/200 [00:44<00:26,  3.02it/s] 61%|██████    | 122/200 [00:46<00:51,  1.51it/s] 62%|██████▏   | 123/200 [00:47<00:43,  1.75it/s] 62%|██████▏   | 124/200 [00:47<00:39,  1.95it/s] 63%|██████▎   | 126/200 [00:48<00:33,  2.19it/s] 64%|██████▎   | 127/200 [00:48<00:35,  2.06it/s] 64%|██████▍   | 129/200 [00:49<00:27,  2.59it/s] 65%|██████▌   | 130/200 [00:49<00:26,  2.64it/s] 66%|██████▌   | 131/200 [00:50<00:31,  2.17it/s] 71%|███████   | 142/200 [00:52<00:14,  4.05it/s] 72%|███████▏  | 143/200 [00:52<00:14,  3.90it/s] 72%|███████▎  | 145/200 [00:53<00:13,  4.11it/s] 73%|███████▎  | 146/200 [00:53<00:17,  3.17it/s] 74%|███████▎  | 147/200 [00:54<00:22,  2.35it/s] 74%|███████▍  | 149/200 [00:55<00:17,  2.91it/s] 75%|███████▌  | 150/200 [00:55<00:16,  3.02it/s] 76%|███████▌  | 152/200 [00:56<00:16,  2.86it/s] 76%|███████▋  | 153/200 [00:56<00:17,  2.63it/s] 77%|███████▋  | 154/200 [00:57<00:16,  2.80it/s] 78%|███████▊  | 155/200 [00:57<00:15,  2.96it/s] 78%|███████▊  | 156/200 [00:57<00:14,  2.94it/s] 79%|███████▉  | 158/200 [00:59<00:24,  1.68it/s] 80%|███████▉  | 159/200 [00:59<00:21,  1.92it/s] 80%|████████  | 160/200 [01:03<00:53,  1.34s/it] 81%|████████  | 162/200 [01:04<00:39,  1.03s/it] 82%|████████▏ | 164/200 [01:05<00:27,  1.32it/s] 82%|████████▎ | 165/200 [01:05<00:23,  1.52it/s] 83%|████████▎ | 166/200 [01:05<00:19,  1.76it/s] 84%|████████▎ | 167/200 [01:06<00:17,  1.88it/s] 88%|████████▊ | 176/200 [01:08<00:07,  3.35it/s] 88%|████████▊ | 177/200 [01:08<00:06,  3.38it/s] 90%|████████▉ | 179/200 [01:09<00:07,  2.89it/s] 90%|█████████ | 180/200 [01:09<00:06,  3.11it/s] 90%|█████████ | 181/200 [01:10<00:06,  2.85it/s] 91%|█████████ | 182/200 [01:10<00:06,  2.88it/s] 92%|█████████▏| 184/200 [01:10<00:04,  3.99it/s] 92%|█████████▎| 185/200 [01:11<00:03,  4.34it/s] 94%|█████████▍| 188/200 [01:11<00:02,  4.70it/s] 94%|█████████▍| 189/200 [01:11<00:02,  4.20it/s] 95%|█████████▌| 190/200 [01:12<00:02,  4.04it/s] 96%|█████████▌| 191/200 [01:12<00:02,  4.18it/s] 96%|█████████▋| 193/200 [01:13<00:03,  2.22it/s] 97%|█████████▋| 194/200 [01:14<00:02,  2.37it/s] 98%|█████████▊| 195/200 [01:15<00:02,  1.87it/s] 98%|█████████▊| 197/200 [01:15<00:01,  2.55it/s] 99%|█████████▉| 198/200 [01:15<00:00,  2.71it/s]100%|█████████▉| 199/200 [01:16<00:00,  2.91it/s]100%|██████████| 200/200 [01:16<00:00,  2.63it/s]
============ Serving Benchmark Result ============
Successful requests:                     200       
Benchmark duration (s):                  76.13     
Total input tokens:                      25400     
Total generated tokens:                  22239     
Request throughput (req/s):              2.63      
Output token throughput (tok/s):         292.12    
Total Token throughput (tok/s):          625.75    
---------------Time to First Token----------------
Mean TTFT (ms):                          589.41    
Median TTFT (ms):                        322.00    
P99 TTFT (ms):                           1342.81   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          96.91     
Median TPOT (ms):                        96.41     
P99 TPOT (ms):                           126.31    
---------------Inter-token Latency----------------
Mean ITL (ms):                           97.57     
Median ITL (ms):                         74.64     
P99 ITL (ms):                            321.30    
==================================================
�?SUCCESS input_len=128 batch_size=32
---

