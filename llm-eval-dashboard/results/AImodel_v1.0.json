{
  "project_id": "yyz_test_20250723_1000",
  "timestamp": "2025-07-17T011:00:15.593620Z",
  "model_name": "DeepSeek",
  "run_mode": "acc-then-bench",
  "base_info": {
    "device": "AIModel-32G",
    "model": "gptq-Qwen2.5-7B-Instruct",
    "version": "1.0",
    "software_version":"",
    "software_url": "",
    "vllm_image_harbor": {
      "huoshan_harbor_url": "",
      "shanghai_harbor_url": ""
    }
  },
  "tests": [
    {
      "test_type": "benchmark",
      "results": [
        {
          "timestamp": 0,
          "concurrency": 1,
          "input_tokens": 32,
          "output_tokens": 32,
          "expected_input": 32,
          "expected_output": 32,
          "avg_input": 32,
          "avg_output": 32,
          "total_time": 4.28,
          "req_throughput": 0.23,
          "output_throughput": 7.47,
          "total_throughput": 14.95,
          "avg_ttft": 616.47,
          "p99_ttft": 0
        },
        {
          "timestamp": 0,
          "concurrency": 2,
          "input_tokens": 32,
          "output_tokens": 32,
          "expected_input": 32,
          "expected_output": 32,
          "avg_input": 32,
          "avg_output": 32,
          "total_time": 2.95,
          "req_throughput": 0.68,
          "output_throughput": 10.83,
          "total_throughput": 21.69,
          "avg_ttft": 650.67,
          "p99_ttft": 0
        },
        {
          "timestamp": 0,
          "concurrency": 3,
          "input_tokens": 32,
          "output_tokens": 32,
          "expected_input": 32,
          "expected_output": 32,
          "avg_input": 32,
          "avg_output": 32,
          "total_time": 2.17,
          "req_throughput": 1.38,
          "output_throughput": 14.76,
          "total_throughput": 29.49,
          "avg_ttft": 661.93,
          "p99_ttft": 0
        },
        {
          "timestamp": 0,
          "concurrency": 4,
          "input_tokens": 32,
          "output_tokens": 32,
          "expected_input": 32,
          "expected_output": 32,
          "avg_input": 32,
          "avg_output": 32,
          "total_time": 1.39,
          "req_throughput": 2.88,
          "output_throughput": 22.98,
          "total_throughput": 46.04,
          "avg_ttft": 602.81,
          "p99_ttft": 0
        },
        {
          "timestamp": 0,
          "concurrency": 1,
          "input_tokens": 128,
          "output_tokens": 128,
          "expected_input": 128,
          "expected_output": 128,
          "avg_input": 128,
          "avg_output": 128,
          "total_time": 15.53,
          "req_throughput": 0.06,
          "output_throughput": 8.24,
          "total_throughput": 16.48,
          "avg_ttft": 693.57,
          "p99_ttft": 0
        },
        {
          "timestamp": 0,
          "concurrency": 2,
          "input_tokens": 128,
          "output_tokens": 128,
          "expected_input": 128,
          "expected_output": 128,
          "avg_input": 128,
          "avg_output": 128,
          "total_time": 11.25,
          "req_throughput": 0.18,
          "output_throughput": 11.38,
          "total_throughput": 22.76,
          "avg_ttft": 1204.48,
          "p99_ttft": 0
        },
        {
          "timestamp": 0,
          "concurrency": 3,
          "input_tokens": 128,
          "output_tokens": 128,
          "expected_input": 128,
          "expected_output": 128,
          "avg_input": 128,
          "avg_output": 128,
          "total_time": 8.43,
          "req_throughput": 0.36,
          "output_throughput": 15.19,
          "total_throughput": 30.37,
          "avg_ttft": 1321.01,
          "p99_ttft": 0
        },
        {
          "timestamp": 0,
          "concurrency": 4,
          "input_tokens": 128,
          "output_tokens": 128,
          "expected_input": 128,
          "expected_output": 128,
          "avg_input": 128,
          "avg_output": 128,
          "total_time": 6.49,
          "req_throughput": 0.62,
          "output_throughput": 19.74,
          "total_throughput": 39.44,
          "avg_ttft": 6075.01,
          "p99_ttft": 0
        },
        {
          "timestamp": 0,
          "concurrency": 1,
          "input_tokens": 512,
          "output_tokens": 512,
          "expected_input": 512,
          "expected_output": 512,
          "avg_input": 512,
          "avg_output": 512,
          "total_time": 62.51,
          "req_throughput": 0.02,
          "output_throughput": 8.19,
          "total_throughput": 16.38,
          "avg_ttft": 2178.37,
          "p99_ttft": 0
        },
        {
          "timestamp": 0,
          "concurrency": 2,
          "input_tokens": 512,
          "output_tokens": 512,
          "expected_input": 512,
          "expected_output": 512,
          "avg_input": 512,
          "avg_output": 512,
          "total_time": 45.43,
          "req_throughput": 0.04,
          "output_throughput": 11.27,
          "total_throughput": 22.54,
          "avg_ttft": 3823.8,
          "p99_ttft": 0
        },
        {
          "timestamp": 0,
          "concurrency": 3,
          "input_tokens": 512,
          "output_tokens": 512,
          "expected_input": 512,
          "expected_output": 512,
          "avg_input": 512,
          "avg_output": 512,
          "total_time": 35.00,
          "req_throughput": 0.09,
          "output_throughput": 14.65,
          "total_throughput": 29.26,
          "avg_ttft": 5672.96,
          "p99_ttft": 0
        },
        {
          "timestamp": 0,
          "concurrency": 4,
          "input_tokens": 512,
          "output_tokens": 512,
          "expected_input": 512,
          "expected_output": 512,
          "avg_input": 512,
          "avg_output": 512,
          "total_time": 22.81,
          "req_throughput": 0.17,
          "output_throughput": 22.45,
          "total_throughput": 44.90,
          "avg_ttft": 7060.31,
          "p99_ttft": 0
        },
        {
          "timestamp": 0,
          "concurrency": 1,
          "input_tokens": 1024,
          "output_tokens": 1024,
          "expected_input": 1024,
          "expected_output": 1024,
          "avg_input": 1024,
          "avg_output": 1024,
          "total_time": 128.97,
          "req_throughput": 0.01,
          "output_throughput": 7.94,
          "total_throughput": 15.88,
          "avg_ttft": 4850.47,
          "p99_ttft": 0
        },
        {
          "timestamp": 0,
          "concurrency": 2,
          "input_tokens": 1024,
          "output_tokens": 1024,
          "expected_input": 1024,
          "expected_output": 1024,
          "avg_input": 1024,
          "avg_output": 1024,
          "total_time": 94.90,
          "req_throughput": 0.02,
          "output_throughput": 10.79,
          "total_throughput": 21.58,
          "avg_ttft": 9103.47,
          "p99_ttft": 0
        },
        {
          "timestamp": 0,
          "concurrency": 3,
          "input_tokens": 1024,
          "output_tokens": 1024,
          "expected_input": 1024,
          "expected_output": 1024,
          "avg_input": 1024,
          "avg_output": 1024,
          "total_time": 75.02,
          "req_throughput": 0.04,
          "output_throughput": 13.65,
          "total_throughput": 27.30,
          "avg_ttft": 18900.98,
          "p99_ttft": 0
        },
        {
          "timestamp": 0,
          "concurrency": 4,
          "input_tokens": 1024,
          "output_tokens": 1024,
          "expected_input": 1024,
          "expected_output": 1024,
          "avg_input": 1024,
          "avg_output": 1024,
          "total_time": 48.90,
          "req_throughput": 0.08,
          "output_throughput": 20.94,
          "total_throughput": 41.88,
          "avg_ttft": 18574.77,
          "p99_ttft": 0
        },
        {
          "timestamp": 0,
          "concurrency": 1,
          "input_tokens": 4096,
          "output_tokens": 1024,
          "expected_input": 4096,
          "expected_output": 1024,
          "avg_input": 4096,
          "avg_output": 1024,
          "total_time": 177.47,
          "req_throughput": 0.01,
          "output_throughput": 5.77,
          "total_throughput": 28.85,
          "avg_ttft": 45599.82,
          "p99_ttft": 0
        },
        {
          "timestamp": 0,
          "concurrency": 2,
          "input_tokens": 4096,
          "output_tokens": 1024,
          "expected_input": 4096,
          "expected_output": 1024,
          "avg_input": 4096,
          "avg_output": 1024,
          "total_time": 147.98,
          "req_throughput": 0.01,
          "output_throughput": 6.92,
          "total_throughput": 34.60,
          "avg_ttft": 73861.98,
          "p99_ttft": 0
        },
        {
          "timestamp": 0,
          "concurrency": 3,
          "input_tokens": 4096,
          "output_tokens": 1024,
          "expected_input": 4096,
          "expected_output": 1024,
          "avg_input": 4096,
          "avg_output": 1024,
          "total_time": 124.42,
          "req_throughput": 0.02,
          "output_throughput": 8.23,
          "total_throughput": 41.15,
          "avg_ttft": 93404.24,
          "p99_ttft": 0
        },
        {
          "timestamp": 0,
          "concurrency": 4,
          "input_tokens": 4096,
          "output_tokens": 1024,
          "expected_input": 4096,
          "expected_output": 1024,
          "avg_input": 4096,
          "avg_output": 1024,
          "total_time": 98.84,
          "req_throughput": 0.04,
          "output_throughput": 10.36,
          "total_throughput": 51.80,
          "avg_ttft": 115986.8,
          "p99_ttft": 0
        }
      ],
      "log_path": ""
    },
    {
      "test_type": "accuracy",
      "datasets": [
        {
          "name": "AIModel_v1.0",
          "dataset_name": "ceval",
          "dataset_pretty_name": "C-Eval",
          "dataset_description": null,
          "model_name": "ceval",
          "score": 0.6985,
          "metrics": [
            {
              "name": "AverageAccuracy",
              "num": 1346,
              "score": 0.6985,
              "macro_score": 0.6952,
              "categories": [
                {
                  "name": [
                    "Humanities"
                  ],
                  "num": 257,
                  "score": 0.7145,
                  "macro_score": 0.7145,
                  "subsets": [
                    {
                      "name": "modern_chinese_history",
                      "score": 0.8261,
                      "num": 23
                    },
                    {
                      "name": "ideological_and_moral_cultivation",
                      "score": 0.9474,
                      "num": 19
                    },
                    {
                      "name": "logic",
                      "score": 0.5455,
                      "num": 22
                    },
                    {
                      "name": "law",
                      "score": 0.5,
                      "num": 24
                    },
                    {
                      "name": "chinese_language_and_literature",
                      "score": 0.6,
                      "num": 23
                    },
                    {
                      "name": "art_studies",
                      "score": 0.6788,
                      "num": 33
                    },
                    {
                      "name": "professional_tour_guide",
                      "score": 0.6966,
                      "num": 29
                    },
                    {
                      "name": "legal_professional",
                      "score": 0.6783,
                      "num": 23
                    },
                    {
                      "name": "high_school_chinese",
                      "score": 0.4526,
                      "num": 19
                    },
                    {
                      "name": "high_school_history",
                      "score": 0.85,
                      "num": 20
                    },
                    {
                      "name": "middle_school_history",
                      "score": 0.9545,
                      "num": 22
                    }
                  ]
                },
                {
                  "name": [
                    "Other"
                  ],
                  "num": 384,
                  "score": 0.7012,
                  "macro_score": 0.7012,
                  "subsets": [
                    {
                      "name": "civil_servant",
                      "score": 0.6979,
                      "num": 47
                    },
                    {
                      "name": "sports_science",
                      "score": 0.7895,
                      "num": 19
                    },
                    {
                      "name": "plant_protection",
                      "score": 0.6818,
                      "num": 22
                    },
                    {
                      "name": "basic_medicine",
                      "score": 0.7895,
                      "num": 19
                    },
                    {
                      "name": "clinical_medicine",
                      "score": 0.8091,
                      "num": 22
                    },
                    {
                      "name": "urban_and_rural_planner",
                      "score": 0.7174,
                      "num": 46
                    },
                    {
                      "name": "accountant",
                      "score": 0.7102,
                      "num": 49
                    },
                    {
                      "name": "fire_engineer",
                      "score": 0.6774,
                      "num": 31
                    },
                    {
                      "name": "environmental_impact_assessment_engineer",
                      "score": 0.7097,
                      "num": 31
                    },
                    {
                      "name": "tax_accountant",
                      "score": 0.6653,
                      "num": 49
                    },
                    {
                      "name": "physician",
                      "score": 0.5837,
                      "num": 49
                    }
                  ]
                },
                {
                  "name": [
                    "STEM"
                  ],
                  "num": 485,
                  "score": 0.6438,
                  "macro_score": 0.6438,
                  "subsets": [
                    {
                      "name": "electrical_engineer",
                      "score": 0.5838,
                      "num": 37
                    },
                    {
                      "name": "metrology_engineer",
                      "score": 0.7167,
                      "num": 24
                    },
                    {
                      "name": "high_school_mathematics",
                      "score": 0.3333,
                      "num": 18
                    },
                    {
                      "name": "high_school_physics",
                      "score": 0.6316,
                      "num": 19
                    },
                    {
                      "name": "high_school_chemistry",
                      "score": 0.6737,
                      "num": 19
                    },
                    {
                      "name": "high_school_biology",
                      "score": 0.7684,
                      "num": 19
                    },
                    {
                      "name": "middle_school_mathematics",
                      "score": 0.6316,
                      "num": 19
                    },
                    {
                      "name": "middle_school_biology",
                      "score": 0.9429,
                      "num": 21
                    },
                    {
                      "name": "middle_school_physics",
                      "score": 0.9474,
                      "num": 19
                    },
                    {
                      "name": "middle_school_chemistry",
                      "score": 0.93,
                      "num": 20
                    },
                    {
                      "name": "veterinary_medicine",
                      "score": 0.7478,
                      "num": 23
                    },
                    {
                      "name": "computer_network",
                      "score": 0.5895,
                      "num": 19
                    },
                    {
                      "name": "operating_system",
                      "score": 0.5789,
                      "num": 19
                    },
                    {
                      "name": "computer_architecture",
                      "score": 0.6952,
                      "num": 21
                    },
                    {
                      "name": "college_programming",
                      "score": 0.7243,
                      "num": 37
                    },
                    {
                      "name": "college_physics",
                      "score": 0.5684,
                      "num": 19
                    },
                    {
                      "name": "college_chemistry",
                      "score": 0.475,
                      "num": 24
                    },
                    {
                      "name": "advanced_mathematics",
                      "score": 0.3368,
                      "num": 19
                    },
                    {
                      "name": "probability_and_statistics",
                      "score": 0.4889,
                      "num": 18
                    },
                    {
                      "name": "discrete_mathematics",
                      "score": 0.2375,
                      "num": 16
                    }
                  ]
                },
                {
                  "name": [
                    "Social Science"
                  ],
                  "num": 220,
                  "score": 0.8182,
                  "macro_score": 0.8182,
                  "subsets": [
                    {
                      "name": "college_economics",
                      "score": 0.5745,
                      "num": 55
                    },
                    {
                      "name": "business_administration",
                      "score": 0.703,
                      "num": 33
                    },
                    {
                      "name": "marxism",
                      "score": 0.9368,
                      "num": 19
                    },
                    {
                      "name": "mao_zedong_thought",
                      "score": 0.9917,
                      "num": 24
                    },
                    {
                      "name": "education_science",
                      "score": 0.7103,
                      "num": 29
                    },
                    {
                      "name": "teacher_qualification",
                      "score": 0.8409,
                      "num": 44
                    },
                    {
                      "name": "high_school_politics",
                      "score": 0.8947,
                      "num": 19
                    },
                    {
                      "name": "high_school_geography",
                      "score": 0.8421,
                      "num": 19
                    },
                    {
                      "name": "middle_school_politics",
                      "score": 1,
                      "num": 21
                    },
                    {
                      "name": "middle_school_geography",
                      "score": 0.8667,
                      "num": 12
                    }
                  ]
                }
              ]
            }
          ],
          "analysis": "N/A"
        }
      ],
      "log_path": ""
    }
  ]
}

